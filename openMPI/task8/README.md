# MPI Task 8: Ping-Pong with MPI_Sendrecv

## Описание задачи

Модифицировать программу из задания 3, используя операцию одновременного выполнения передачи и приема данных (`MPI_Sendrecv`). Сравнить результаты вычислительных экспериментов.

## Отличия от Task 3

### Task 3 (исходная версия)
Использует раздельные операции:
- `MPI_Send` - отправка данных
- `MPI_Recv` - прием данных

Процессы выполняют операции последовательно:
```cpp
if (rank == 0) {
    MPI_Send(...);  // Сначала отправка
    MPI_Recv(...);  // Потом прием
} else {
    MPI_Recv(...);  // Сначала прием
    MPI_Send(...);  // Потом отправка
}
```

### Task 8 (модифицированная версия)
Использует комбинированную операцию:
- `MPI_Sendrecv` - одновременная отправка и прием

Оба процесса выполняют операции одновременно:
```cpp
// Оба процесса выполняют одну операцию
MPI_Sendrecv(send_buf, ..., dest, ...,
             recv_buf, ..., source, ..., ...);
```

## Преимущества MPI_Sendrecv

1. **Упрощение кода**: одна операция вместо двух
2. **Предотвращение deadlock**: MPI гарантирует корректное выполнение
3. **Потенциально лучшая производительность**: MPI может оптимизировать одновременную передачу
4. **Безопасность**: автоматическое управление буферами

## Структура проекта

```
openMPI/task8/
├── main.cpp           # Основная программа с MPI_Sendrecv
├── Makefile           # Сборка проекта
├── job.sh             # SLURM скрипт (2 ноды фиксированно)
├── job_auto.sh        # SLURM скрипт (автоматическое размещение)
├── plot_graphs.py     # Визуализация результатов
├── README.md          # Этот файл
├── QUICKSTART.md      # Быстрый старт
├── SUMMARY.md         # Итоговая сводка
├── data.csv           # Результаты (2 ноды фиксированно)
├── data_auto.csv      # Результаты (автоматическое размещение)
└── graphs/            # Графики
```

## Конфигурации запуска

### 1. Fixed (2 ноды фиксированно) - job.sh
- **Параметры**: `--nodes=2 --ntasks-per-node=1`
- **Размещение**: Процессы гарантированно на разных узлах
- **Коммуникация**: Через сеть (межузловая)
- **Файл результатов**: `data.csv`

### 2. Auto (автоматическое размещение) - job_auto.sh
- **Параметры**: `--ntasks=2`
- **Размещение**: Планировщик решает сам (может быть на одном узле)
- **Коммуникация**: Зависит от размещения (shared memory или сеть)
- **Файл результатов**: `data_auto.csv`

## Запуск

### На кластере (SLURM)

**Запуск обоих экспериментов:**
```bash
sbatch job.sh       # Fixed (2 ноды)
sbatch job_auto.sh  # Auto (планировщик)
```

**Визуализация результатов:**
```bash
python3 plot_graphs.py
```

### Локально
```bash
make clean
make
mpirun -np 2 ./program > data.csv
python3 plot_graphs.py
```

## Параметры эксперимента

- **Количество процессов**: 2 (ping-pong требует ровно 2 процесса)
- **Размеры сообщений**: от 0 байт до 16 МБ (степени двойки)
- **Количество итераций**:
  - 1000 для сообщений ≤ 64 КБ
  - 100 для сообщений 64 КБ - 1 МБ
  - 20 для сообщений > 1 МБ

## Метрики

1. **Время передачи (Time)**: среднее время одной передачи в секундах
2. **Пропускная способность (Bandwidth)**: скорость передачи данных в МБ/сек

## Создаваемые графики

### Отдельные графики для каждой конфигурации:
1. **time_vs_size_fixed.png** - время передачи (Fixed)
2. **bandwidth_vs_size_fixed.png** - пропускная способность (Fixed)
3. **time_vs_size_auto.png** - время передачи (Auto)
4. **bandwidth_vs_size_auto.png** - пропускная способность (Auto)

### Сравнительные графики:
5. **comparison_time.png** - сравнение времени Fixed vs Auto
6. **comparison_bandwidth.png** - сравнение пропускной способности
7. **comparison_latency.png** - латентность для малых сообщений
8. **comparison_speedup.png** - относительная производительность

## Ожидаемые результаты

### Fixed (2 ноды):
- Большая латентность (процессы на разных узлах)
- Стабильная пропускная способность сети
- Реалистичные условия для распределенных вычислений

### Auto (планировщик):
- Может быть меньше латентность (если процессы на одном узле)
- Может быть выше пропускная способность (shared memory)
- Зависит от загрузки кластера

## Формат данных

CSV файл с разделителем `;`:
```
Bytes;Iterations;Time;Bandwidth
0;1000;1.247235e-04;0.0000
1;1000;1.266438e-04;0.0075
...
```

## Анализ результатов

При сравнении конфигураций обратите внимание на:
1. **Латентность (0 байт)**: разница между Fixed и Auto
2. **Пропускная способность**: максимальные значения для больших сообщений
3. **Стабильность**: вариативность результатов
4. **Speedup**: отношение времени Auto к Fixed

## Технические детали

- **Компилятор**: mpic++ с оптимизацией -O3
- **MPI реализация**: OpenMPI
- **Язык**: C++
- **Стандарт**: C++11 и выше

## Зачем две конфигурации?

Ping-pong всегда использует ровно 2 процесса, поэтому масштабируемость не тестируется. Однако сравнение двух конфигураций показывает:

- **Fixed**: Реалистичный сценарий для распределенных вычислений (процессы на разных узлах)
- **Auto**: Оптимальное размещение планировщиком (может использовать shared memory)

Это помогает понять влияние типа коммуникации на производительность.